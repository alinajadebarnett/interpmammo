<div class="row g-5 mb-5">
  <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">What We Do</h3>
    Our research focuses on developing and improving machine learning tools used in breast imaging and diagnosis (mammography), so that those in clinical settings can make better decisions. 
    <br><br>
    Many commercialized 'black box' models are incapable of explaining the inner workings of their decision making. This is problematic, given the potentially life-changing nature of diagnosis made from mammograms. To help both doctors and patients understand the rationale behind any automated decision, we work on designing <i>inherently </i>interpretable models that produce not only accurate, but also explainable, traceable results. 
    <br><br>

    <h4>With Interpretability</h4>
    <div class="row g-5 mb-5">
      <div class="col-md-6">
        <img src="{{ site.github.url }}/assets/img/with_interp.jpg" alt="with_interp" width="100%">
      </div>
      <div class="col-md-6">
        <ul>
          <br>
          <li>See supporting evidence for the decision</li>
          <li>Can easily disregard predictions where the model reasoning is wrong</li>
          <li>Give appropriate level of trust to model decision for current clinical decision</li>
          <li>Extracted medical features may be useful even when end prediction is incorrect</li>
        </ul>
      </div>
    </div>

    <br><br>

    <h4>Without Interpretability</h4>
    <div class="row g-5 mb-5">
      <div class="col-md-6">
        <img src="{{ site.github.url }}/assets/img/without_interp.jpg" alt="without_interp" width="100%">
      </div>
      <div class="col-md-6">
        <ul>
          <br>
          <li>Blind to inner working of decision</li>
          <li>Cannot assess whether model is using relevant evidence or confounders</li>
          <li>No way to verify current patient decision</li>
          <li>No way to check system failure</li>
          <li>Only model validation is on test set</li>
        </ul>
      </div>
    </div>

    <br><br>

    Our <a href="https://rdcu.be/cDhJ7">interpretable AI algorithm for breast lesions (IAIA-BL)</a>, for example, predicts malignancy of mass legions by comparing them to learned prototypes that are each linked to a clinically relevant feature, which are then analyzed and aggregated to inform the final decision. Thus, IAIA-BL is a tool that can be understood and verified by medical practitioners, rather than one designed to replace them entirely. 

    <br><br>
  
    <img src="{{ site.github.url }}/assets/img/iaia-bl.jpg" alt="iaia-bl" width="100%">

    <br><br>

    We work towards making interpretability a default setting in clinical practices, and continue to find areas in mammography that can be improved. 

    <br><br>
    
    To view more papers, navigate to our <b><a href="{{ site.github.url }}/publications">publications</a></b> page. 



  </div>

  <!-- <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">Longer Overview</h3>
    Detailed explanation of the work we've done so far, and where we are headed to. 
  </div> -->
</div>
